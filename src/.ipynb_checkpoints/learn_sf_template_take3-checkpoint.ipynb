{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# VERSION WITH AudioReader\n",
    "\n",
    "# Import audio processing modules\n",
    "\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import audioread\n",
    "import librosa\n",
    "import os\n",
    "# import seaborn as sns\n",
    "\n",
    "from audio_read import AudioReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def half_rectify(n):\n",
    "    return np.fmax(n, np.zeros_like(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def spectral_flux(spec):\n",
    "    \"\"\"\n",
    "    Computes the spectral flux of a spectrogram\n",
    "    :param spec: a 2-D array of floats\n",
    "    :return: a numpy array\n",
    "    \"\"\"\n",
    "    return np.expand_dims(np.sum(np.square(half_rectify(np.absolute(spec[:, 1:]) -\n",
    "                                         np.absolute(spec[:, :-1]))), 0), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import ML modules\n",
    "\n",
    "import sklearn.neighbors as nbrs\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ML params - set dataset and algorithm\n",
    "\n",
    "sample_dirs = [\"../audio/samples/onsets/ALFRED/\", \"../audio/samples/onsets/DANBY/\"]\n",
    "\n",
    "# clf_KNN = nbrs.KNeighborsClassifier(n_neighbors=5)\n",
    "# clf_SVM = SVC()\n",
    "# clf_forest = RandomForestClassifier(verbose=1, warm_start=True)\n",
    "clf_SGD = SGDClassifier(loss='log', penalty='l2', verbose=0, fit_intercept=False)\n",
    "\n",
    "# clfs = [clf_KNN, clf_SVM, clf_forest]\n",
    "clfs = [clf_SGD]\n",
    "# clfs = [clf_forest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Audio params\n",
    "\n",
    "# filename = \"../audio/SBI-1_20090915_234016.wav\"\n",
    "# annotation_path = \"../annotations/SBI-1_20090915_HAND_LOW_IDaek_EDITED_with_HIGH.txt\"\n",
    "# model_path = \"../features/SBI_coefs_41.npy\"\n",
    "\n",
    "# Load audio and compute spectrogram\n",
    "sr = 24000.0\n",
    "n_fft = 256 # =win_length\n",
    "win_length = n_fft\n",
    "hop_length = 128\n",
    "hop_size = hop_length/sr # in seconds\n",
    "win_size = win_length/sr # in seconds\n",
    "spec_dt = hop_length/sr # in seconds\n",
    "truncate = 64  # throw out freq bins below this index\n",
    "\n",
    "# Define length of coefficient window\n",
    "w_length = 1    # let's just use odd numbered values, ok?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert segment of spectrogram into ML features\n",
    "\n",
    "def make_feature(spec, spec_dt, w_length):\n",
    "    l = spec.shape[1]\n",
    "    mid = l/2;\n",
    "    start = mid - np.floor((w_length)/2)\n",
    "    end = start + w_length\n",
    "\n",
    "    # Choose which version of SF to use\n",
    "#     sf = np.square(half_rectify(np.absolute(spec[:, start:end]) -\n",
    "#                                      np.absolute(spec[:, start-1:end-1])))\n",
    "    sf = (half_rectify(np.absolute(spec[:, start:end]) -\n",
    "                                     np.absolute(spec[:, start-1:end-1])))\n",
    "    return sf.reshape(1, sf.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# y, _ = librosa.load(\"../audio/samples/onsets/ALFRED/true_123676.wav\", sr=sr)\n",
    "# spec = np.flipud(np.abs(librosa.core.stft(y, n_fft=n_fft, hop_length=hop_length)))\n",
    "\n",
    "# plt.figure(figsize=(10,5))\n",
    "# plt.imshow(spec)\n",
    "# # plt.plot(sf)\n",
    "# plt.imshow(spec[40:, start:end])\n",
    "# # plt.imshow(spec[40:, start-1:end-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train\n",
    "import random\n",
    "\n",
    "n_epochs = 50\n",
    "for epoch in range(n_epochs):\n",
    "    print \"Epoch \" + str(epoch)\n",
    "    for sample_dir in sample_dirs:\n",
    "            d = os.listdir(sample_dir)\n",
    "#             random.shuffle(d)\n",
    "            for f in d:\n",
    "                if f[-4:] != '.wav':\n",
    "                    continue\n",
    "                y, _ = librosa.load(sample_dir + f, sr=sr)\n",
    "\n",
    "                # Make feature\n",
    "                spec = librosa.core.stft(y, n_fft=n_fft, hop_length=hop_length)\n",
    "                feature = make_feature(spec[truncate:,:], spec_dt, w_length)\n",
    "\n",
    "                # Make label\n",
    "                if f[0] == 't':\n",
    "                    label = np.asarray([1])\n",
    "                elif f[0] == 'f':\n",
    "                    label = np.asarray([0])\n",
    "                else:\n",
    "                    print \"BAD FILENAMES!\"\n",
    "                    exit()\n",
    "                \n",
    "                # Fit feature\n",
    "                for clf in clfs:\n",
    "#                     clf.partial_fit(feature, label, classes=[0,1])\n",
    "                    clf.fit(feature, label)\n",
    "# return clfs\n",
    "print \"All done!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Debuggy stuff\n",
    "\n",
    "model = clfs[0]\n",
    "print model\n",
    "print w_length\n",
    "coefs2 = model.coef_.reshape((n_fft/2 + 1 - truncate, w_length))\n",
    "coefs = model.coef_\n",
    "# np.save('model_59.npy', coefs)\n",
    "print coefs.shape\n",
    "plt.imshow((coefs2), interpolation='nearest', aspect='auto', cmap='hot')\n",
    "\n",
    "np.argmax(coefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_feature_set(spec, spec_dt, annotation_path, w_length):\n",
    "    \"\"\"\n",
    "    Generates features and labels from spectrogram.\n",
    "    :param spec: NxM numpy array\n",
    "    :param spec_dt: float\n",
    "    :param annotation_path: String\n",
    "    :param w_length: int\n",
    "    :return: features, labels\n",
    "    \"\"\"\n",
    "    if annotation_path is not None:\n",
    "        df = pd.read_csv(annotation_path, header=None, \n",
    "            names=['onsets', 'offsets', 'label'], delimiter='\\t')\n",
    "        onsets = np.asarray(df['onsets'])\n",
    "        offsets = np.asarray(df['offsets'])\n",
    "\n",
    "    num_features = spec.shape[1]-w_length+1\n",
    "\n",
    "    # Generate features\n",
    "    features = [[]] * num_features\n",
    "    for i in xrange(num_features):\n",
    "    \tfeatures[i] = np.ravel(spec[:, i:i+w_length])\n",
    "\n",
    "    # Generate labels\n",
    "    if annotation_path is not None:\n",
    "        labels = np.zeros(num_features)\n",
    "        for on in onsets:\n",
    "            start = int(np.round((on-0.100)/spec_dt))\n",
    "            finish = int(np.round((on+0.100)/spec_dt))\n",
    "            labels[start:finish+1] = 1\n",
    "        return np.asarray(features).T, labels\n",
    "\n",
    "    return np.asarray(features).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "######## Evaluate model\n",
    "test_path = '../audio/NSDNS_20110902_192900.wav'\n",
    "detection_curve_path = '../detection_functions/NSDNS_SF_71.npy'\n",
    "# test_path = '../audio/ALFRED_20110924_183200.wav'\n",
    "# detection_curve_path = '../detection_functions/ALFRED_SF_50_test.npy'\n",
    "\n",
    "# Optional - load model\n",
    "# coefs = np.load(model_path)\n",
    "# c = coefs.reshape(645,1)\n",
    "\n",
    "# Iterate through signal by large blocks (constrained by RAM)\n",
    "duration = None          #seconds\n",
    "num_hops_per_block = 30000    # Hops\n",
    "block_len = (num_hops_per_block+w_length-1)*hop_length # Samples\n",
    "block_size = 1.0*block_len/sr # Seconds\n",
    "\n",
    "# Preallocate detection curve to save time\n",
    "if duration is None:\n",
    "    # If duration is None, we are looking at whole file. We use audioread to\n",
    "    # check out the wav header and find the duration and sample rate\n",
    "    with audioread.audio_open(test_path) as f:\n",
    "        det_curve_len = int(np.floor(f.duration*f.samplerate/(hop_length*num_hops_per_block))*num_hops_per_block)\n",
    "else:\n",
    "    # Else we know the duration; we can calculate the detection curve's length directly\n",
    "    det_curve_len = int(np.floor(duration*sr/(hop_length*num_hops_per_block))*num_hops_per_block)\n",
    "detection_curve = np.zeros((1,det_curve_len))\n",
    "print det_curve_len\n",
    "\n",
    "\n",
    "block_i = 0\n",
    "reader = AudioReader(test_path, sr=sr, channels=1)\n",
    "\n",
    "print \"Starting eval with params duration={}, block_len={}\".format(duration, num_hops_per_block)\n",
    "\n",
    "while not reader.done():\n",
    "    # Read the next chunk of samples.\n",
    "    print \"Testing next block... i={} \".format(block_i) + str(time.clock())\n",
    "    y, sr = reader.read(block_size)\n",
    "    if len(y) < block_size*sr or (duration is not None and offset > duration):\n",
    "        print \"last one!\"\n",
    "        # Not quite right - throwing out last bit of data\n",
    "        break\n",
    "#         done = True\n",
    "    D = librosa.core.stft(y, n_fft=n_fft, hop_length=hop_length)\n",
    "\n",
    "    # Transform frames of spec into vector\n",
    "    features = np.asarray(make_feature_set(D[truncate:,:], spec_dt, annotation_path=None, \n",
    "        w_length=w_length))\n",
    "\n",
    "    # Apply almost all of SF algorithm\n",
    "    actual_features = np.square(half_rectify(np.absolute(features[:, 1:]) -\n",
    "                                     np.absolute(features[:, :-1])))\n",
    "\n",
    "    # Weighted SF\n",
    "    detection_curve[0][num_hops_per_block*block_i:num_hops_per_block*(block_i+1)] = np.dot(coefs, actual_features)    \n",
    "    \n",
    "    # Unweighted SF\n",
    "#     detection_curve[0][num_hops_per_block*block_i:num_hops_per_block*(block_i+1)] = np.dot(np.ones_like(coefs), actual_features) \n",
    "\n",
    "    reader.sample_position -= w_length*hop_length\n",
    "    block_i += 1\n",
    "\n",
    "print spec_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print test_res.shape\n",
    "# print sf_res.shape\n",
    "\n",
    "# diff_res = test_res-sf_res\n",
    "# print np.min(diff_res)\n",
    "# print np.max(diff_res)\n",
    "# plt.imshow(diff_res[:,:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print detection_curve.shape\n",
    "print detection_curve[:10]\n",
    "# print detection_curve[0,:]\n",
    "# detection_curve_path += 'off1'\n",
    "detection_curve_path = '../detection_functions/NSDNS_SF_71_off3.npy'\n",
    "\n",
    "print detection_curve_path\n",
    "np.save(detection_curve_path, detection_curve[0,3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# detection_curve = detection_curve[1:]\n",
    "# detection_curve -= min(detection_curve)\n",
    "# detection_curve /= max(detection_curve)\n",
    "# plt.plot(detection_curve[0,29000:31000])\n",
    "plt.plot(detection_curve[0,:])\n",
    "# onsets = np.nonzero(actual_labels)\n",
    "# plt.plot([onsets[0],onsets[0]], [-40,40], 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.argmax(detection_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "actual_labels[6280:6295]\n",
    "np.nonzero(actual_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### This is a separate program. Visualizes the average spectrogram for all \n",
    "#   audio containing/not containing flight calls\n",
    "\n",
    "true_spec = None\n",
    "false_spec = None\n",
    "for sample_dir in sample_dirs:\n",
    "    d = os.listdir(sample_dir)\n",
    "    for f in d:\n",
    "        if f[-4:] != '.wav':\n",
    "            continue\n",
    "        y, _ = librosa.load(sample_dir + f, sr=sr)\n",
    "\n",
    "        # Make feature\n",
    "        spec = librosa.core.stft(y, n_fft=n_fft, hop_length=hop_length)\n",
    "#         feature = make_feature(spec[truncate:,:], spec_dt, w_length)\n",
    "\n",
    "        # Make label\n",
    "        if f[0] == 't':\n",
    "            if true_spec is None:\n",
    "                true_spec = spec\n",
    "            else:\n",
    "                true_spec += spec\n",
    "        elif f[0] == 'f':\n",
    "            if false_spec is None:\n",
    "                false_spec = spec\n",
    "            else:\n",
    "                false_spec += spec\n",
    "        else:\n",
    "            print \"BAD FILENAMES!\"\n",
    "            exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# normalize\n",
    "true_spec = np.abs(true_spec)\n",
    "false_spec = np.abs(false_spec)\n",
    "true_spec /= np.max(true_spec)\n",
    "false_spec /= np.max(false_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(np.log(true_spec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(np.log(false_spec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "diff_spec = ((np.log(true_spec)-np.log(false_spec)))[:,20:40]\n",
    "plt.imshow(diff_spec/np.max(diff_spec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
